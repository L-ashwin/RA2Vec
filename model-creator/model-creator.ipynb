{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import gensim, logging\n",
    "from gensim.test.utils import get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino = pd.read_csv('./data/mapping.csv', index_col = 0)\n",
    "amino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_sprot = './data/uniprot_sprot.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transDict(trans, amino):\n",
    "    if trans == 'ProtVec':\n",
    "        return None\n",
    "\n",
    "    dic = {}\n",
    "    for i in range(amino.shape[0]):\n",
    "        dic[ord(amino['one_letter_code'][i])] = ord(amino[trans][i])\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGenerator(object):\n",
    "    def __init__(self, filename, gms=3, transDict=None):\n",
    "        self.filename = filename\n",
    "        self.gms = gms\n",
    "        self.transDict = transDict\n",
    "        self.skipCount = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        fasta_sequences = SeqIO.parse(open(self.filename), 'fasta')\n",
    "        \n",
    "        for entry in fasta_sequences:        \n",
    "            seq = str(entry.__dict__['_seq'])\n",
    "            \n",
    "            if (any(ele in seq for ele in ['B', 'J', 'O', 'U', 'X', 'Z'])) and (transDict != None):\n",
    "                continue\n",
    "                    \n",
    "            if self.transDict != None:\n",
    "                seq = seq.translate(self.transDict)\n",
    "                \n",
    "            for i in range(self.gms):\n",
    "                sentense = []\n",
    "                for j in range(0, len(seq), self.gms):\n",
    "                    word = seq[(i+j) : ((i+j) + self.gms)]\n",
    "                    if len(word) == self.gms:\n",
    "                        sentense.append(word)\n",
    "\n",
    "                yield(sentense)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word2vec_model(sentenceGenerator, model_name, size, window, kgrams, workers=11, min_count = 1, epochs = 5):\n",
    "    \n",
    "    model_name = f'./data/models/RA2V_{model_name}_G{kgrams}_S{size}_W{window}.model'\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) \n",
    "\n",
    "    path = get_tmpfile(model_name)\n",
    "    \n",
    "    model = gensim.models.Word2Vec(\n",
    "        sentences = sentenceGenerator, \n",
    "        min_count = min_count, \n",
    "        \n",
    "        size = size, \n",
    "        window = window,\n",
    "        workers=workers,\n",
    "        iter=epochs,\n",
    "        sg=1)\n",
    "    \n",
    "    print('model trained successfully....')\n",
    "    model.save(model_name)\n",
    "    model.delete_temporary_training_data()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        \n",
    "        from collections import namedtuple\n",
    "        from itertools import product\n",
    "        \n",
    "        Run = namedtuple('Run', params.keys())\n",
    "        \n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "            \n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'kGrams'   : [3,4,5]\n",
    "    ,'vecSize' : [25,50,75]\n",
    "    ,'window'  : [5]\n",
    "    ,'trans'   : ['Hydropathy','Conf_sim']\n",
    "}\n",
    "runs = RunBuilder.get_runs(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    \n",
    "    print(f'kGrams:{run.kGrams} vecSize:{run.vecSize} window:{run.window} trans:{run.trans}')\n",
    "    \n",
    "    transDict = get_transDict(run.trans, amino)\n",
    "\n",
    "    sentenceGenerator = SentenceGenerator(\n",
    "        filename = uniprot_sprot, \n",
    "        gms      = run.kGrams, \n",
    "        transDict=transDict)\n",
    "\n",
    "    model = train_word2vec_model(\n",
    "        sentenceGenerator, \n",
    "        model_name = run.trans, \n",
    "        size       = run.vecSize, \n",
    "        window     = run.window ,\n",
    "        kgrams     = run.kGrams,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
